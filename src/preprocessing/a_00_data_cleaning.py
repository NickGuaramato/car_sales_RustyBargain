#a_00_data_cleaning

import pandas as pd
import numpy as np

from pathlib import Path

from typing import Tuple

from src.utils.helpers import fill_missing_values, normalize_names, directs
from src.utils.config_manager import load_paths
from src.utils.logging_config import setup_logging

PATHS = load_paths()["dirs"]
logger = setup_logging(module='data_cleaning')

def load_data(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    return normalize_names(df)

#Cambiando tipo de datos
def convert_data_types(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    # Fechas
    date_cols = ['date_crawled', 'date_created', 'last_seen']
    for col in date_cols:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], format='%d/%m/%Y %H:%M', errors='coerce')
    
    # CategÃ³ricas - Â¡VersiÃ³n mejorada!
    categorical_cols = ['vehicle_type', 'gearbox', 'fuel_type']
    for col in categorical_cols:
        if col in df.columns:
            df[col] = df[col].astype('category')

    return df

#Eliminando columnas no necesarias
def unnecessary_columns(df: pd.DataFrame) -> pd.DataFrame:
    columns_to_drop = ['number_of_pictures',
                       'date_crawled', 
                       'date_created', 
                       'last_seen', 
                       'postal_code']
    return df.drop(columns_to_drop, axis=1)

#Tratando valores duplicados
def remove_duplicates(df: pd.DataFrame) -> pd.DataFrame:
    return df.drop_duplicates()

#Filtrando y acotando datos para columna del aÃ±o de registro (registration_year)
def filter_data(df: pd.DataFrame) -> pd.DataFrame:
    df = df.query('1900 <= registration_year <= 2024')
#filtrando precio para valores mayores o iguales a 100 (price)
    df = df.query('price >= 100')
#Limitando valores en la columna de potencia  y sustituyendo valores atÃ­picos con valores NaN(power) 
    df = df.query('power <= 2000')
#reemplazo
    df.loc[df['power'] < 45, 'power'] = np.nan

#Tratando valores atÃ­picos. Mes 0 (registration_month)
#Reemplanzando con la mediana
    df = df.copy()
    df.loc[df['registration_month'] == 0, 'registration_month'] = df['registration_month'].median()
    df.loc[:, 'registration_month'] = df['registration_month'].astype('int')

    return df

#FunciÃ³n moda. Usando en columnas de datos categÃ³ricos faltantes
def process_missing_values(df: pd.DataFrame) -> pd.DataFrame:

    #vehicle_type
    df = fill_missing_values(
        df,
        groups_cols=['brand', 'model'],
        target_col='vehicle_type'
    )
    #gearbox
    df = fill_missing_values(
        df,
        groups_cols=['brand', 'model'],
        target_col='gearbox'
    )
    #fuel_type
    if 'fuel_type' in df.columns:
        df['fuel_type'] = df['fuel_type'].replace('petrol', 'gasoline')
        df = fill_missing_values(df, ['model'], 'fuel_type')

    #model
    df = fill_missing_values(
        df,
        ['model'],
        'fuel_type'
    )
    #model
    df = fill_missing_values(
        df,
        groups_cols=['brand', 'registration_year'],
        target_col='model'
    )
    #filtrando a power
    df['power'] = pd.to_numeric(df['power'], errors='coerce')#cambio tipo de dato a nÃºmerico
    df = fill_missing_values(
        df,
        ['model'],
        'power',
        method='median'
    )

    if 'not_repaired' in df.columns:
        df['not_repaired'] = df['not_repaired'].map({'yes': 1, 'no': 0}).fillna(0).astype(int)  # â† ConversiÃ³n directa a binario
    
    # Eliminar nulos como en monolito
    df = df.dropna(subset=['not_repaired', 'power'])

    categorical_cols = ['vehicle_type', 'gearbox', 'fuel_type']
    for col in categorical_cols:
        if col in df.columns and col in df.columns:
            df[col] = df[col].astype('category')  # Forzar tipo
    
    return df

def analyze_data(df: pd.DataFrame) -> dict:
    directs()
    #DistribuciÃ³n. Variable objetivo 'price' (logarÃ­tmico)
    log_price = np.log1p(df['price'])
    #Resumen de estadÃ­stica descriptiva del precio original respecto a la transformaciÃ³n
#EstadÃ­sticas descriptivas del precio original
    stats = {
        "price_stats": pd.DataFrame({
            "Precio Original": df['price'].describe(),
            "Precio Transformado (Log)": log_price.describe()
        }),
        #AnÃ¡lisis de distribuciÃ³n de columnas categÃ³ricas
        
        "categorical_columns" : {
            col:df.groupby(col, observed=True)['price'].mean().sort_values(ascending=False)#se agregÃ³ observed=True
            for col in ['vehicle_type', 'fuel_type', 'gearbox', 'not_repaired', 'brand']
        },
        #AnÃ¡lisis de distribuciÃ³n de columnas nÃºmericas
        
        "numeric_columns": df[['registration_year', 'power', 'registration_month']].describe(),
        "cleaned_stats": df.describe(include='all')        
        }
    #luego de limipieza(estadÃ­sticas)
    stats["cleaned_stats"].to_csv(Path(PATHS["metrics"]) / " preprocessed_data_statistics.csv", 
                                          index=True
                                          )
    
    stats["price_stats"].to_csv(Path(PATHS["metrics"]) / "stats_price(ori)_price(log).csv", 
                                          index=True
                                          )

    return stats

def preprocess_data(input_path: str) -> pd.DataFrame:
    directs()

    logger.info(f"ðŸš€ Iniciando preprocesamiento desde: {input_path}")

    #estadisticas de dataset original
    df_raw = pd.read_csv(input_path)
    
    logger.info(f"ðŸ“Š Dataset original cargado. Shape: {df_raw.shape}")

    df_raw.describe(include='all').to_csv(Path(PATHS["metrics"]) / "original_data_statistics.csv", 
                                          index=True
                                          )
    #ejecuciÃ³n de todo el pipeline
    df = load_data(input_path)
    df = convert_data_types(df)
    df = unnecessary_columns(df)

    logger.debug(f"ðŸ”„ DespuÃ©s de limpieza bÃ¡sica. Columnas: {len(df.columns)}")

    df= remove_duplicates(df)

    logger.info(f"ðŸ§¹ Duplicados eliminados. Filas: {df.shape[0]}")
    
    df.to_pickle(Path(PATHS["metrics"]) / "unduplicated_data.pkl")
    df.describe(include='all').to_csv(Path(PATHS["metrics"]) / "unduplicated_data_stats.csv", 
                                      index=True
                                      )

    df = filter_data(df)

    logger.info(f"ðŸŽ¯ DespuÃ©s de filtros. Filas: {df.shape[0]}")

    df = process_missing_values(df)

    logger.info(f"ðŸ”§ Valores faltantes procesados. Â¿Nulos?: {df.isnull().sum().sum() == 0}")

    assert df.isnull().sum().sum() == 0, "Â¡Quedan valores nulos!"

    logger.info("âœ… ValidaciÃ³n pasada: Cero valores nulos")

    df.to_pickle(Path(PATHS["metrics"]) / "preprocessed_data.pkl")
    df.describe(include='all').to_csv(Path(PATHS["metrics"]) / "preprocessed_stats.csv", 
                                      index=True
                                      )#datos preprocesados (antes de features_engineer)

    logger.debug("ðŸ’¾ Datos preprocesados guardados")

    stats = analyze_data(df)

    logger.info("ðŸŽ‰ Preprocesamiento completado exitosamente")

    return df, stats