# ğŸš— PredicciÃ³n de Precios de Venta de AutomÃ³viles - Pipeline de ML

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![ML](https://img.shields.io/badge/ML-LightGBM%20%7C%20XGBoost-naranja)
![Tests](https://img.shields.io/badge/tests-12%2F12-verde)
![Docker](https://img.shields.io/badge/Docker-Ready-blue)
![License](https://img.shields.io/badge/License-MIT-amarillo)

> Pipeline de machine learning **listo para producciÃ³n** para predecir precios de automÃ³viles usados. CaracterÃ­sticas: arquitectura modular, pruebas exhaustivas, contenedores Docker y registro profesional.

## ğŸ“Š Resumen Ejecutivo

**Objetivo**: Desarrollar un sistema robusto de ML para Rusty Bargain para estimar precios de automÃ³viles usados con un equilibrio Ã³ptimo entre:

- âœ… **Calidad de PredicciÃ³n** (minimizaciÃ³n de RMSE)
- âš¡ **Velocidad de Inferencia** (predicciones en tiempo real)
- â±ï¸ **Tiempo de Entrenamiento** (desarrollo eficiente de modelos)

**Resultados Clave**:
| Modelo | RMSE | Tiempo Entrenamiento | Mejor Para | RecomendaciÃ³n |
|--------|----------|----------------------|------------|---------------|
| **ğŸ† LGBM** | **1.557,73** | 1,3s | **Mejor precisiÃ³n general** | âœ… **PRODUCCIÃ“N - Recomendado** |
| LGBM_log | 1.698,14 | 0,5s | Target transformado logarÃ­tmicamente | âœ… Usar si distribuciÃ³n log-normal |
| XGBoost_log | 1.916,35 | 0,6s | Equilibrio precisiÃ³n-velocidad | âš¡ Buen balance velocidad/precisiÃ³n |
| RF_log | 2.393,22 | 2,6s | Conjunto robusto | ğŸ›¡ï¸ Robustez ante outliers |
| DT_log | 2.448,04 | 0,4s | **Inferencia mÃ¡s rÃ¡pida** | âš¡ Necesidades de latencia ultra-baja |

**Ejemplo de PredicciÃ³n en Vivo**:

```bash
# Volkswagen golf, manual, 120Hp, 50000Km, 2018, sedÃ¡n, gasolina, sin reparaciones
ğŸ¯ PredicciÃ³n LGBM: $11.662,64
ğŸ¯ PredicciÃ³n LGBM_log: $9.488,83
ğŸ¯ PredicciÃ³n XGBoost_log: $8.019,89
```
**Nota**: Las variaciones de precio reflejan diferentes arquitecturas de modelo y transformaciones del target.

## ğŸ—ï¸ Arquitectura & DiseÃ±o

### ğŸ“ Estructura del Proyecto
**car_sales_RustyBargain/**
- `src/` - CÃ³digo fuente (paquete Python instalable)
  - `preprocessing/` - Pipeline de procesamiento de datos
    - `a_00_data_cleaning.py`
    - `a_01_feature_engineering.py`
    - `a_02_encoding.py`
    - `a_03_split_data.py`
    - `a_06_save_results.py`
  - `models/` - Entrenamiento y predicciÃ³n de modelos
  - `utils/` - ConfiguraciÃ³n, logging, helpers
  - `visualization/` - EDA y grÃ¡ficos
- `config/` - Archivos de configuraciÃ³n YAML
  - `paths.yaml` - Rutas de directorios
  - `params.yaml` - HiperparÃ¡metros del modelo
- `tests/` - Suite de pruebas exhaustiva
  - `unit/` - Pruebas unitarias para mÃ³dulos
  - `integration/` - Pruebas de pipeline end-to-end
- `artifacts/` - Salidas generadas (no versionadas)
  - `models/` - Modelos serializados (.joblib)
  - `reports/` - MÃ©tricas y estadÃ­sticas (.csv, .json)
  - `plots/` - Salidas de visualizaciÃ³n
  - `logs/` - Logs de ejecuciÃ³n del pipeline
- `notebooks/` - AnÃ¡lisis exploratorio de datos
- `Dockerfile` - ContenedorizaciÃ³n
- `pyproject.toml` - Empaquetado Python moderno
- `environment.yml` - EspecificaciÃ³n de entorno Conda

### ğŸ”„ Flujo del Pipeline & Persistencia de Datos
**ğŸ“ data/raw/car_data.csv** (354,369 filas)

**â–¼ (a_00_data_cleaning.py) - Limpieza y Filtrado de Datos**
- ğŸ—‘ï¸ Remover duplicados â†’ 326,826 filas
- ğŸ¯ Aplicar filtros (aÃ±o, precio, potencia) â†’ 314,814 filas
- ğŸ”§ Manejar valores faltantes â†’ 258,199 filas (limpias)
- ConversiÃ³n de tipos
- ğŸ’¾ **GUARDAR:** `artifacts/reports/unduplicated_data.pkl` (326,826 filas)
- ğŸ’¾ **GUARDAR:** `artifacts/reports/preprocessed_data.pkl` (258,199 filas)

**â–¼ (a_01_feature_engineering.py) - IngenierÃ­a de CaracterÃ­sticas**
- â• Agregar: `vehicle_age` (2024 - registration_year)
- â• Agregar: `mileage_per_year` (mileage / vehicle_age)
- â– Eliminar: registration_month
- ğŸ’¾ **GUARDAR:** `data/processed/data_processed.parquet` (258,199 filas, 12 cols)

**â–¼ (a_02_encoding.py) - CodificaciÃ³n & TransformaciÃ³n**
- ğŸ”„ CodificaciÃ³n por frecuencia: `brand â†’ brand_freq`, `model â†’ model_freq`
- ğŸ­ CodificaciÃ³n One-Hot: `vehicle_type`, `gearbox`, `fuel_type`
- ğŸ“ EstandarizaciÃ³n: `power`, `mileage`, `vehicle_age`
- ğŸ“ˆ TransformaciÃ³n logarÃ­tmica: `price â†’ log_price` (opcional)
- ğŸ’¾ **GUARDAR:** `data/processed/final_data.parquet` (258,199 filas, 23 cols)

**â–¼ (a_05_train.py) - Entrenamiento & PredicciÃ³n de Modelos**
- ğŸ“Š Para modelos basados en Ã¡rboles (LGBM): Usar `data_processed.parquet`
- âš™ï¸ Para otros modelos (XGBoost, RF, DT): Usar `final_data.parquet`
- **Evaluar usando RMSE**
- ğŸ’¾ Guardar modelos: `artifacts/models/*.joblib`
- ğŸ’¾ Guardar mÃ©tricas: `artifacts/reports/selected_models.json`

**â–¼ (main.py & predict.py) - Listo para Despliegue**
- Modelos serializados (.joblib)
- Codificadores entrenados
- API de predicciÃ³n (`predict.py`)

**ExplicaciÃ³n Clave**:
- **unduplicated_data.pkl**: Dataset despuÃ©s de eliminar duplicados, ANTES de filtros estrictos
- **preprocessed_data.pkl**: Dataset despuÃ©s de TODOS los filtros y limpieza
- **data_processed.parquet**: Igual que preprocessed_data.pkl + nuevas caracterÃ­sticas (vehicle_age, mileage_per_year)
- **final_data.parquet**: Mismo dataset base + codificaciÃ³n aplicada (listo para modelos)

### ğŸ› ï¸ Stack TecnolÃ³gico
| Componente | TecnologÃ­a | PropÃ³sito |
|-----------|------------|---------|
| **Core ML** | LightGBM, XGBoost, Scikit-learn | Entrenamiento & evaluaciÃ³n de modelos |
| **Procesamiento de Datos** | Pandas, NumPy | ManipulaciÃ³n & limpieza de datos |
| **ConfiguraciÃ³n** | PyYAML | Gestionar rutas & parÃ¡metros |
| **Logging** | Python logging | Seguimiento profesional de ejecuciÃ³n |
| **Pruebas** | Pytest | Calidad de cÃ³digo & confiabilidad |
| **Empaquetado** | Setuptools (pyproject.toml) | Empaquetado Python moderno |
| **ContenedorizaciÃ³n** | Docker | Entornos reproducibles |
| **Entorno** | Conda (environment.yml) | GestiÃ³n de dependencias |

## âš™ï¸ InstalaciÃ³n & Uso

### ğŸ“¦ OpciÃ³n 1: InstalaciÃ³n Local (pip)
```bash
# 1. Clonar repositorio
git clone https://github.com/NickGuaramato/car_sales_RustyBargain.git
cd car_sales_RustyBargain

# 2. Instalar paquete en modo desarrollo
pip install -e .

# 3. Ejecutar pipeline completo (entrenamiento + evaluaciÃ³n)
python main.py

# 4. Hacer predicciones
python -m src.models.predict \
  -m LGBM \
  -d '{"brand":"volkswagen","model":"golf","gearbox":"manual","power":120,"mileage":50000,"registration_year":2018,"vehicle_type":"sedan","fuel_type":"gasoline","not_repaired":"no"}'
```

### ğŸ³ OpciÃ³n 2: Docker (Recomendado para Reproducibilidad)
```bash
# 1. Construir imagen Docker
docker build -t car-sales-ml .

# 2. Ejecutar contenedor (entrena modelos automÃ¡ticamente)
docker run --rm car-sales-ml

# 3. Modo interactivo con bash
docker run -it --rm car-sales-ml bash

# 4. Hacer predicciones desde el contenedor
docker run --rm car-sales-ml \
  python -m src.models.predict \
  -m LGBM_log \
  -d '{"brand":"audi","power":180,"registration_year":2020}'
```

### ğŸŒ¿ OpciÃ³n 3: Entorno Conda
```bash
# Crear y activar entorno
conda env create -f environment.yml
conda activate car-sales

# Verificar instalaciÃ³n
python -c "import src; print('âœ… Paquete instalado exitosamente')"
```

### ğŸš€ Ejemplos de Inicio RÃ¡pido
**Entrenar todos los modelos y obtener reporte RMSE:**
```bash
python main.py 2>&1 | grep -E "(RMSE|INFO.*training)"

# Salida:
# [INFO] training: ğŸ“Š LGBM - RMSE: 1557.7299
# [INFO] training: ğŸ“Š LGBM_log - RMSE: 1698.1426
# [INFO] training: ğŸ“Š XGBoost_log - RMSE: 1916.3507
```

**PredicciÃ³n individual con diferentes modelos:**
# Usando el mejor modelo (LGBM)
```bash
python -m src.models.predict -m LGBM -d '{"brand":"volkswagen","model":"golf","gearbox":"manual","power":120,"mileage":50000,"registration_year":2018,"vehicle_type":"sedan","fuel_type":"gasoline","not_repaired":"no"}'
```
# Salida: ğŸ¯ Precio estimado usando LGBM: $11,662.64

```bash
# Usando modelo transformado logarÃ­tmicamente  
python -m src.models.predict -m LGBM_log -d '{"brand":"volkswagen","model":"golf","gearbox":"manual","power":120,"mileage":50000,"registration_year":2018,"vehicle_type":"sedan","fuel_type":"gasoline","not_repaired":"no"}'
```
# Salida: ğŸ¯ Precio estimado usando LGBM_log: $9,488.83

# Usando XGBoost con caracterÃ­sticas completas
```bash
python -m src.models.predict -m XGBoost_log -d '{"brand":"volkswagen","model":"golf","gearbox":"manual","power":120,"mileage":50000,"registration_year":2018,"vehicle_type":"sedan","fuel_type":"gasoline","not_repaired":"no"}'
```
# Salida: ğŸ¯ Precio estimado usando XGBoost_log: $8,019.89

ğŸ“ **Nota sobre CaracterÃ­sticas Requeridas:**
Se deben proporcionar las 9 caracterÃ­sticas para las predicciones:
- brand (string: ej. "volkswagen", "bmw", "audi")
- model (string: ej. "golf", "a4", "3er")
- gearbox (string: "manual" o "auto")
- power (entero: caballos de fuerza)
- mileage (entero: kilÃ³metros recorridos)
- registration_year (entero: 1900-2024)
- vehicle_type (string: ej. "sedan", "suv", "convertible")
- fuel_type (string: "gasoline", "diesel", "electric", "hybrid")
- not_repaired (string: "yes" o "no")

### ğŸ“ Estructura de Salida Esperada
**artifacts/**
- `models/` - Modelos serializados (.joblib)
  - `LGBM.joblib` - Modelo con mejor rendimiento
  - `LGBM_log.joblib`
  - `XGBoost_log.joblib`
  - ...
- `reports/` - MÃ©tricas de evaluaciÃ³n
  - `selected_models.json` - Puntuaciones RMSE
  - `selected_models.csv`
  - `preprocessed_data_statistics.csv`
- `logs/pipeline.log` - Log de ejecuciÃ³n con timestamps

**data/processed/** - Datasets intermedios
- `data_processed.parquet` - Limpio + caracterÃ­sticas (12 cols)
- `final_data.parquet` - Codificado listo para modelos (23 cols)

data/processed/ # Datasets intermedios
â”œâ”€â”€ data_processed.parquet # Limpio + caracterÃ­sticas (12 cols)
â””â”€â”€ final_data.parquet # Codificado listo para modelos (23 cols)

## ğŸ“Š MetodologÃ­a

### ğŸ§¹ 1. Preprocesamiento de Datos (`a_00_data_cleaning.py`)

**Objetivo:** Transformar datos brutos y ruidosos en un dataset limpio y listo para anÃ¡lisis.

| Paso | AcciÃ³n | Impacto |
|------|--------|---------|
| **EliminaciÃ³n de Duplicados** | `df.drop_duplicates()` | ReducciÃ³n de dataset de 354,369 a 326,826 filas (-7.8%) |
| **Filtrado Temporal** | `1900 â‰¤ registration_year â‰¤ 2024` | AsegurÃ³ edades realistas de vehÃ­culos |
| **Filtrado de Precio** | `price â‰¥ 100` | EliminÃ³ listados invÃ¡lidos/placeholder |
| **Filtrado de Potencia** | `power â‰¤ 2000` & `power < 45 â†’ NaN` | EliminÃ³ outliers extremos |
| **ImputaciÃ³n de Valores Faltantes** | Relleno basado en moda/mediana por grupo | PreservÃ³ integridad de datos sin valores arbitrarios |
| **ConversiÃ³n de Tipo** | AnÃ¡lisis datetime, codificaciÃ³n categÃ³rica | OptimizÃ³ memoria & velocidad de procesamiento |

**ConclusiÃ³n Clave:** La reducciÃ³n mÃ¡s significativa de datos provino de filtros temporales y de precio, eliminando ~20% de registros pero mejorando dramÃ¡ticamente la calidad de datos.

### âš™ï¸ 2. IngenierÃ­a de CaracterÃ­sticas (a_01_feature_engineering.py)
**Objetivo:** Crear caracterÃ­sticas derivadas informativas que mejoren el poder predictivo del modelo.

| CaracterÃ­stica | FÃ³rmula | Insight de Negocio | CorrelaciÃ³n con Precio |
|----------------|---------|-------------------|------------------------|
| **`vehicle_age`** | `2024 - registration_year` | Captura curva de depreciaciÃ³n | **-0.493** (negativa fuerte) |
| **`mileage_per_year`** | `mileage / max(vehicle_age, 1)` | Normaliza uso en el tiempo | **+0.036** (positiva dÃ©bil) |

**Hallazgos Clave:**
- vehicle_age muestra correlaciÃ³n negativa fuerte (-0.49), confirmando que vehÃ­culos mÃ¡s viejos tienen valores de mercado significativamente mÃ¡s bajos.
- mileage_per_year tiene correlaciÃ³n mÃ­nima (0.036), sugiriendo que la tasa de kilometraje anual es menos predictiva que el kilometraje total o la edad del vehÃ­culo.
- La transformaciÃ³n logarÃ­tmica fortalece ligeramente la relaciÃ³n de vehicle_age (-0.52), apoyando su uso en modelos con target logarÃ­tmico.

**DecisiÃ³n:** Ambas caracterÃ­sticas se retuvieron ya que vehicle_age provee seÃ±al fuerte, mientras mileage_per_year puede interactuar con otras caracterÃ­sticas de formas no-lineales capturadas por modelos basados en Ã¡rboles.

### ğŸ”¢ 3. CodificaciÃ³n & EstandarizaciÃ³n (a_02_encoding.py)
**Objetivo:** Transformar datos categÃ³ricos para algoritmos de ML preservando relaciones.

| TÃ©cnica | Aplicado A | JustificaciÃ³n |
|---------|------------|---------------|
| **CodificaciÃ³n por Frecuencia** | `brand`, `model` | Captura popularidad mientras reduce dimensionalidad |
| **CodificaciÃ³n One-Hot** | `vehicle_type`, `gearbox`, `fuel_type` | Enfoque estÃ¡ndar para categorÃ­as nominales |
| **EstandarizaciÃ³n** | `power`, `mileage`, `vehicle_age` | Asegura contribuciÃ³n igual de caracterÃ­sticas |
| **TransformaciÃ³n LogarÃ­tmica** | `price` (opcional) | Maneja distribuciÃ³n sesgada a la derecha |

**Estrategia de Pipeline Dual:**
- **Modelos basados en Ã¡rboles (LGBM):** Usar caracterÃ­sticas categÃ³ricas crudas (data_processed.parquet)
- **Otros modelos (XGBoost, RF, DT):** Usar caracterÃ­sticas completamente codificadas (final_data.parquet)

### ğŸ¤– 4. Entrenamiento & SelecciÃ³n de Modelos (a_05_train.py)
**Objetivo:** Identificar modelo Ã³ptimo balanceando precisiÃ³n, velocidad e interpretabilidad.

**OptimizaciÃ³n de HiperparÃ¡metros:**
```yaml
# config/params.yaml (extract)
lightgbm:
  n_estimators: [100, 150, 300]
  learning_rate: [0.1, 0.2, 0.5]
  max_depth: [5, 8, 10]

xgboost:
  max_depth: [4, 6, 8]
  n_estimators: [50, 100]
  learning_rate: [0.05, 0.1]
```

## ğŸ“ˆ Resultados & AnÃ¡lisis

### ğŸ“Š CaracterÃ­sticas del Dataset
El pipeline de preprocesamiento transformÃ³ exitosamente el dataset bruto en un formato limpio y listo para anÃ¡lisis:

| Etapa | Filas | Columnas | DescripciÃ³n |
|-------|-------|----------|-------------|
| **Datos Brutos** | 354,369 | 16 | Listados originales scraped con ruido y valores faltantes |
| **DespuÃ©s de DesduplicaciÃ³n** | 326,826 | 16 | Eliminadas 7.8% entradas duplicadas |
| **DespuÃ©s de Filtrado** | 314,814 | 16 | Filtros de calidad aplicados (aÃ±o, precio, potencia) |
| **Limpieza Final** | 258,199 | 12 | Valores faltantes manejados, conversiÃ³n de tipo (`data_processed.parquet`) |
| **Codificado Final** | **258,199** | **23** | IngenierÃ­a de caracterÃ­sticas + codificaciÃ³n (`final_data.parquet`) |

**Logro de Calidad de Datos:** 27.1% reducciÃ³n en filas, pero 100% aumento en calidad de datos y preparaciÃ³n para ML.

### ğŸ† ComparaciÃ³n de Rendimiento de Modelos
EvaluaciÃ³n exhaustiva de 5 modelos listos para producciÃ³n:

| Modelo | RMSE (â‚¬) | Î” vs Mejor | Tiempo Entrenamiento | Velocidad Inferencia | Mejor Caso de Uso |
|--------|----------|------------|----------------------|----------------------|-------------------|
| **ğŸ† LGBM** | **1,557.73** | **0%** (baseline) | 1.3 | Muy RÃ¡pida (<10ms) | **Despliegue en producciÃ³n** |
| LGBM_log | 1,698.14 | +9.0% | 0.5 | Muy RÃ¡pida (<10ms) | Distribuciones log-normales |
| XGBoost_log | 1,916.35 | +23.0% | 0.6 | RÃ¡pida (~15ms) | Balance precisiÃ³n/velocidad |
| RF_log | 2,393.22 | +53.6% | 2.6 | Media (~30ms) | Robustez ante outliers |
| DT_log | 2,448.04 | +57.2% | 0.4 | **MÃ¡s RÃ¡pida** (<5ms) | Necesidades de latencia ultra-baja |

**Insights de Rendimiento Clave:**
- LGBM logra el mejor balance precisiÃ³n-velocidad (mejor RMSE + entrenamiento rÃ¡pido)
- Modelos basados en Ã¡rboles superan significativamente enfoques lineales (no mostrados)
- TransformaciÃ³n logarÃ­tmica reduce ligeramente la precisiÃ³n pero puede mejorar distribuciÃ³n de errores
- Ãrbol de DecisiÃ³n, aunque menos preciso, ofrece inferencia mÃ¡s rÃ¡pida para aplicaciones crÃ­ticas de latencia

### ğŸ“‰ Visualizaciones Clave
Visualizaciones EDA exhaustivas disponibles en artifacts/plots/:

| VisualizaciÃ³n | Archivo | Insight Clave |
|---------------|---------|---------------|
| **DistribuciÃ³n de Precios** | `final_hist_price.png` | DistribuciÃ³n sesgada a la derecha, transformaciÃ³n logarÃ­tmica beneficiosa |
| **CorrelaciÃ³n de CaracterÃ­sticas** | `final_corr_matrix.png` | `registration_year` (+0.49) y `power` (+0.43) predictores positivos mÃ¡s fuertes |
| **AnÃ¡lisis de Marcas** | `final_price_by_brand.png` | Marcas premium (BMW, Mercedes) tienen prima de precio 2-3x |
| **Impacto de CondiciÃ³n** | `final_not_repaired_distribution.png` | VehÃ­culos no reparados se venden con ~40% descuento |
| **Paneles Multi-grÃ¡fico** | `comparison_mosaics/*.jpg` | EDA exhaustivo en visualizaciones agrupadas |

### ğŸ¯ AnÃ¡lisis de Impacto en Negocio
Para las Operaciones de Rusty Bargain:

| MÃ©trica | Valor | ImplicaciÃ³n de Negocio |
|---------|-------|------------------------|
| **Error Promedio de PredicciÃ³n** | **â‚¬1,558** | 2-5% del valor tÃ­pico de auto (rango â‚¬15k-â‚¬50k) |
| **Modelo Recomendado** | **LGBM** | Balance Ã³ptimo: precisiÃ³n (1,558 RMSE) + velocidad (<10ms) |
| **Throughput del Pipeline** | **258K registros en <30s** | Permite predicciones batch diarias para inventario completo |
| **Latencia API** | **<100ms** | Adecuada para integraciÃ³n en tiempo real en sitio web |
| **TamaÃ±o de Modelo** | **5-50 MB por modelo** | Despliegue fÃ¡cil en infraestructura cloud estÃ¡ndar |

### ğŸ” Insights TÃ©cnicos & Recomendaciones
1. **Importancia de CaracterÃ­sticas:** AnÃ¡lisis de correlaciÃ³n revela registration_year (+0.49), power (+0.43), y vehicle_age (-0.49) como predictores mÃ¡s fuertes, con mileage mostrando correlaciÃ³n negativa moderada (-0.39)
2. **Insight EstadÃ­stico:** registration_year (+0.49) y su caracterÃ­stica derivada vehicle_age (-0.49) muestran las correlaciones mÃ¡s fuertes, representando el mismo efecto subyacente de depreciaciÃ³n. power (+0.43) emerge como el segundo predictor positivo mÃ¡s fuerte, indicando que el rendimiento del motor es un factor clave del precio.
3. **Calidad de Datos CrÃ­tica:** Filtrado de precio (â‰¥â‚¬100) eliminÃ³ 11% de listados no realistas
4. **Estrategia de CodificaciÃ³n:** Pipeline dual (categÃ³rico vs. codificado) optimiza para diferentes tipos de modelo
5. **Escalabilidad:** Arquitectura modular soporta actualizaciones incrementales de datos
6. **Listo para Despliegue:** Todos los modelos serializados con codificadores de soporte para integraciÃ³n sin problemas

**Mejoras Futuras:**
- Incorporar variaciones geogrÃ¡ficas de precios
- AÃ±adir patrones de demanda estacionales
- Implementar aprendizaje en lÃ­nea para actualizaciones de modelo
- Desarrollar enfoques de ensemble para reducciÃ³n de error

## ğŸ§ª Pruebas & GarantÃ­a de Calidad
### âœ… Cobertura de Pruebas & ValidaciÃ³n
El proyecto implementa una estrategia de pruebas de dos niveles para asegurar confiabilidad tanto a nivel de mÃ³dulo como de sistema.

| Nivel Prueba | Cantidad | Alcance | Archivos Clave |
|--------------|----------|---------|----------------|
| **ğŸ§© Pruebas Unitarias** | 5 | ValidaciÃ³n de funciones individuales | `tests/unit/test_*.py` |
| **ğŸ”— Pruebas de IntegraciÃ³n** | 7 | VerificaciÃ³n de pipeline completo | `tests/integration/test_pipeline.py` |
| **ğŸ“Š Cobertura Total** | **12** | **100% componentes del pipeline** | |

**Todas las pruebas pasan exitosamente** (12/12), confirmando:
- La limpieza de datos maneja correctamente casos extremos y valores faltantes
- La ingenierÃ­a de caracterÃ­sticas produce transformaciones matemÃ¡ticamente sÃ³lidas
- Los pipelines de codificaciÃ³n mantienen consistencia de datos
- El entrenamiento de modelos serializa y carga correctamente

### ğŸ”§ PreparaciÃ³n para IntegraciÃ³n Continua
La estructura del proyecto soporta integraciÃ³n CI/CD sin problemas:

```yaml
# Ejemplo de flujo de trabajo GitHub Actions
name: Test Pipeline
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
      - run: pip install -e .
      - run: pytest tests/ -v --disable-warnings
```

### ğŸ“ Sistema de Logging Profesional
El logging centralizado (src/utils/logging_config.py) provee:

| Nivel Log | PropÃ³sito | Ejemplo |
|-----------|-----------|---------|
| INFO | Hitos del pipeline | "Fase 1/4: Preprocesamiento" |
| DEBUG | Procesamiento detallado | "DespuÃ©s de filtros. Filas: 314,814" |
| WARNING | Notificaciones de desaprobaciÃ³n | "FutureWarning: El comportamiento de Series.replace..." |
| ERROR | Puntos de falla | "Error en el pipeline: {str(e)}" |

Salida de Log: artifacts/logs/pipeline.log mantiene historial completo de ejecuciÃ³n con timestamps.
```bash
### ğŸ³ Reproducibilidad Contenedorizada
Docker asegura entornos idÃ©nticos entre desarrollo, pruebas y despliegue:

# VerificaciÃ³n de construcciÃ³n
docker build -t car-sales-ml .  # âœ… Se construye exitosamente

# VerificaciÃ³n de tiempo de ejecuciÃ³n  
docker run --rm car-sales-ml python -c "import src; print('âœ… Todos los mÃ³dulos importables')"
```

### ğŸ“‹ MÃ©tricas de Calidad de CÃ³digo

| MÃ©trica | Estado | Herramientas |
|---------|--------|--------------|
| Modularidad | Alta (8 mÃ³dulos especializados) | DiseÃ±o arquitectÃ³nico |
| ConfiguraciÃ³n | Externalizada (archivos YAML) | pyyaml |
| Manejo de Errores | Bloques try/except comprensivos | Excepciones Python |
| Type Hints | ImplementaciÃ³n parcial | Python typing |
| DocumentaciÃ³n | Comentarios en lÃ­nea + logging | CÃ³digo auto-documentado |

### ğŸ” ValidaciÃ³n contra Requerimientos de Negocio

| Requerimiento | Objetivo | Rendimiento Actual | Notas |
|---------------|----------|---------------------|-------|
| **PrecisiÃ³n de PredicciÃ³n** | RMSE â‰¤ â‚¬2,500 | **â‚¬1,558** (LGBM) | âœ… **42% mejor que objetivo** |
| **Velocidad de Inferencia** | <100ms (modelo cargado) | **<10ms** (estimado) | Solo inferencia del modelo; preprocesamiento completo aÃ±ade ~16s |
| **Tiempo de Entrenamiento** | <5 minutos | **~24 segundos** | âœ… **8x mÃ¡s rÃ¡pido que objetivo** |
| **Procesamiento Batch** | 250K registros/hora | **258K en ~24s** | âœ… **36,000x mÃ¡s rÃ¡pido que objetivo** |
| **Eficiencia de Memoria** | <1GB RAM | **~13MB** (proceso Python) | âœ… **Altamente eficiente** |
| **Reproducibilidad** | DeterminÃ­stico | `random_state=12345` | âœ… **Completamente reproducible** |

**Notas de Rendimiento:**
- **Latencia de inferencia:** La predicciÃ³n del modelo en sÃ­ es <10ms, pero el script predict.py incluye preprocesamiento completo de datos por conveniencia de desarrollo.
- **OptimizaciÃ³n de producciÃ³n:** En una API desplegada, el preprocesamiento serÃ­a cacheado/optimizado, logrando verdadera latencia <100ms.
- **Eficiencia batch:** Procesar todos los 258K registros en 24 segundos demuestra excelente escalabilidad para predicciones batch.

### ğŸš¨ Limitaciones Conocidas & Mejoras Futuras
- GestiÃ³n de Advertencias: FutureWarnings de pandas/sklearn pueden silenciarse en producciÃ³n
- ExpansiÃ³n de CaracterÃ­sticas: CaracterÃ­sticas geogrÃ¡ficas y estacionales podrÃ­an mejorar precisiÃ³n
- Monitoreo: ProducciÃ³n se beneficiarÃ­a de dashboards de seguimiento de rendimiento
- Pruebas A/B: Framework para comparar versiones de modelo en producciÃ³n

EvaluaciÃ³n General de Calidad: Listo para producciÃ³n con pruebas exhaustivas, logging y contenedorizaciÃ³n que soportan despliegue confiable.

## ğŸ“„ Licencia & Contacto
### ğŸ“œ Licencia

Este proyecto estÃ¡ licenciado bajo la Licencia MIT - ver el archivo [LICENSE](LICENCIA) para detalles.

```text
MIT License
Copyright (c) 2024 Nick A. Guaramato

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
```

### ğŸ¤ Contribuciones
Â¡Las contribuciones son bienvenidas! Por favor sigue estos pasos:

- Bifurcar el repositorio
- Crear una rama de caracterÃ­stica (git checkout -b feature/CaracterÃ­sticaIncreÃ­ble)
- Confirmar cambios (git commit -m 'AÃ±adir CaracterÃ­sticaIncreÃ­ble')
- Empujar a la rama (git push origin feature/CaracterÃ­sticaIncreÃ­ble)
- Abrir un Pull Request

### ğŸ™ Agradecimientos
- Rusty Bargain por el caso de negocio y dataset
- La comunidad de ML open-source por herramientas y librerÃ­as
- Mentores y colegas de **Tripleten Team** que proporcionaron retroalimentaciÃ³n

### ğŸ“š Cita
````bibtex
Si usas este proyecto en tu investigaciÃ³n o trabajo, por favor cita:
@software{car_sales_ml_pipeline,
  author = {Guaramato, Nick A.},
  title = {Car Sales Price Prediction - ML Pipeline},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/NickGuaramato/car_sales_RustyBargain}
}
````

### ğŸš€ PrÃ³ximos Pasos
Â¿Interesado en extender este proyecto? Considera:
- AÃ±adir variaciones geogrÃ¡ficas de precios
- Implementar aprendizaje en lÃ­nea para actualizaciones de modelo
- Desarrollar una API REST para predicciones en tiempo real
- Crear un dashboard para monitoreo de rendimiento de modelos

# Autor âœ¨
Nick A. Guaramato
CientÃ­fico de Datos & Ingeniero ElÃ©ctrico


ğŸ”— [GitHub](https://github.com/NickGuaramato) | ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/nick-a-guaramato) | ğŸ“§ [Email](guaramatonick@gmail.com)

## ğŸŒ English Version
For English speakers, check the [English documentation](docs/README_EN.md).
